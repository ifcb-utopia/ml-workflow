{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c90d4c6e-acbc-47fb-a790-dbf46d538066",
   "metadata": {},
   "source": [
    "This notebook runs the image generator version of the CNN (based on E. Culhane cnn codes) and uses both the microsoft azure VM for data storage/access, and for running the code. This CNN-v1 is for a basic CNN, and without use of tensorboard image callbacks.\n",
    "The CNN is trained using labeled NAAMES data.\n",
    "A. Chase, Jan 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "808b0f94-7ea3-43d2-86a7-d5b4333710a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import imageio\n",
    "import getpass\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import Callback\n",
    "import datetime\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import imp\n",
    "import cv2\n",
    "\n",
    "import data_utils as du\n",
    "imp.reload(du)\n",
    "import ml_models\n",
    "imp.reload(ml_models)\n",
    "\n",
    "#pip install -r ../requirements.txt\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ea520ec-5d87-46f7-8a73-b1d64a721d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>class_raw</th>\n",
       "      <th>high_group</th>\n",
       "      <th>missing_high_group</th>\n",
       "      <th>id</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>Area</th>\n",
       "      <th>Biovolume</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>...</th>\n",
       "      <th>ScatInt</th>\n",
       "      <th>FluoInt</th>\n",
       "      <th>ScatPeak</th>\n",
       "      <th>FluoPeak</th>\n",
       "      <th>NumberOfROIinTrigger</th>\n",
       "      <th>missing_meta_data</th>\n",
       "      <th>ESDA_exclude</th>\n",
       "      <th>excluded_1</th>\n",
       "      <th>set</th>\n",
       "      <th>binary_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IFCB107D20151104T112022P00433_Unicellular.png</td>\n",
       "      <td>Unicellular</td>\n",
       "      <td>Other</td>\n",
       "      <td>False</td>\n",
       "      <td>IFCB107D20151104T112022P00433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>plankton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IFCB107D20151104T114135P00194_Unicellular.png</td>\n",
       "      <td>Unicellular</td>\n",
       "      <td>Other</td>\n",
       "      <td>False</td>\n",
       "      <td>IFCB107D20151104T114135P00194</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>plankton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IFCB107D20151104T114135P00246_Unicellular.png</td>\n",
       "      <td>Unicellular</td>\n",
       "      <td>Other</td>\n",
       "      <td>False</td>\n",
       "      <td>IFCB107D20151104T114135P00246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>plankton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IFCB107D20151104T124515P00027_Unicellular.png</td>\n",
       "      <td>Unicellular</td>\n",
       "      <td>Other</td>\n",
       "      <td>False</td>\n",
       "      <td>IFCB107D20151104T124515P00027</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>plankton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IFCB107D20151105T174918P00074_Dinophyceae.png</td>\n",
       "      <td>Dinophyceae</td>\n",
       "      <td>Dinoflagellate</td>\n",
       "      <td>False</td>\n",
       "      <td>IFCB107D20151105T174918P00074</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>plankton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998895</th>\n",
       "      <td>IFCB107D20180412T010113P00020_Ceratium.png</td>\n",
       "      <td>Ceratium</td>\n",
       "      <td>Dinoflagellate</td>\n",
       "      <td>False</td>\n",
       "      <td>IFCB107D20180412T010113P00020</td>\n",
       "      <td>40.348</td>\n",
       "      <td>-68.296</td>\n",
       "      <td>1507.093426</td>\n",
       "      <td>20001.839825</td>\n",
       "      <td>2501.816609</td>\n",
       "      <td>...</td>\n",
       "      <td>1.09682</td>\n",
       "      <td>0.36801</td>\n",
       "      <td>3.33541</td>\n",
       "      <td>1.37789</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>plankton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998896</th>\n",
       "      <td>IFCB107D20180412T012434P00137_Ditylum.png</td>\n",
       "      <td>Ditylum</td>\n",
       "      <td>Diatom</td>\n",
       "      <td>False</td>\n",
       "      <td>IFCB107D20180412T012434P00137</td>\n",
       "      <td>40.324</td>\n",
       "      <td>-68.387</td>\n",
       "      <td>4811.591696</td>\n",
       "      <td>91203.058213</td>\n",
       "      <td>6707.612457</td>\n",
       "      <td>...</td>\n",
       "      <td>3.49742</td>\n",
       "      <td>1.77298</td>\n",
       "      <td>3.35693</td>\n",
       "      <td>3.31523</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>plankton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998897</th>\n",
       "      <td>IFCB107D20180412T012434P00348_Ditylum.png</td>\n",
       "      <td>Ditylum</td>\n",
       "      <td>Diatom</td>\n",
       "      <td>False</td>\n",
       "      <td>IFCB107D20180412T012434P00348</td>\n",
       "      <td>40.324</td>\n",
       "      <td>-68.387</td>\n",
       "      <td>2446.626298</td>\n",
       "      <td>30443.529921</td>\n",
       "      <td>3317.560554</td>\n",
       "      <td>...</td>\n",
       "      <td>2.46922</td>\n",
       "      <td>0.90272</td>\n",
       "      <td>3.35900</td>\n",
       "      <td>2.21282</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>plankton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998898</th>\n",
       "      <td>IFCB107D20180412T021117P00330_Ceratium.png</td>\n",
       "      <td>Ceratium</td>\n",
       "      <td>Dinoflagellate</td>\n",
       "      <td>False</td>\n",
       "      <td>IFCB107D20180412T021117P00330</td>\n",
       "      <td>40.273</td>\n",
       "      <td>-68.571</td>\n",
       "      <td>1500.951557</td>\n",
       "      <td>19808.704267</td>\n",
       "      <td>2787.802768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.61201</td>\n",
       "      <td>0.04541</td>\n",
       "      <td>2.85538</td>\n",
       "      <td>0.37142</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>plankton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998899</th>\n",
       "      <td>IFCB107D20180412T021117P00781_Ditylum.png</td>\n",
       "      <td>Ditylum</td>\n",
       "      <td>Diatom</td>\n",
       "      <td>False</td>\n",
       "      <td>IFCB107D20180412T021117P00781</td>\n",
       "      <td>40.273</td>\n",
       "      <td>-68.571</td>\n",
       "      <td>2281.055363</td>\n",
       "      <td>32824.776104</td>\n",
       "      <td>3335.294118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.57738</td>\n",
       "      <td>0.01702</td>\n",
       "      <td>3.33338</td>\n",
       "      <td>0.20818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>plankton</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1998900 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             file_name    class_raw  \\\n",
       "0        IFCB107D20151104T112022P00433_Unicellular.png  Unicellular   \n",
       "1        IFCB107D20151104T114135P00194_Unicellular.png  Unicellular   \n",
       "2        IFCB107D20151104T114135P00246_Unicellular.png  Unicellular   \n",
       "3        IFCB107D20151104T124515P00027_Unicellular.png  Unicellular   \n",
       "4        IFCB107D20151105T174918P00074_Dinophyceae.png  Dinophyceae   \n",
       "...                                                ...          ...   \n",
       "1998895     IFCB107D20180412T010113P00020_Ceratium.png     Ceratium   \n",
       "1998896      IFCB107D20180412T012434P00137_Ditylum.png      Ditylum   \n",
       "1998897      IFCB107D20180412T012434P00348_Ditylum.png      Ditylum   \n",
       "1998898     IFCB107D20180412T021117P00330_Ceratium.png     Ceratium   \n",
       "1998899      IFCB107D20180412T021117P00781_Ditylum.png      Ditylum   \n",
       "\n",
       "             high_group  missing_high_group                             id  \\\n",
       "0                 Other               False  IFCB107D20151104T112022P00433   \n",
       "1                 Other               False  IFCB107D20151104T114135P00194   \n",
       "2                 Other               False  IFCB107D20151104T114135P00246   \n",
       "3                 Other               False  IFCB107D20151104T124515P00027   \n",
       "4        Dinoflagellate               False  IFCB107D20151105T174918P00074   \n",
       "...                 ...                 ...                            ...   \n",
       "1998895  Dinoflagellate               False  IFCB107D20180412T010113P00020   \n",
       "1998896          Diatom               False  IFCB107D20180412T012434P00137   \n",
       "1998897          Diatom               False  IFCB107D20180412T012434P00348   \n",
       "1998898  Dinoflagellate               False  IFCB107D20180412T021117P00330   \n",
       "1998899          Diatom               False  IFCB107D20180412T021117P00781   \n",
       "\n",
       "            lat    long         Area     Biovolume   ConvexArea  ...  ScatInt  \\\n",
       "0           NaN     NaN          NaN           NaN          NaN  ...      NaN   \n",
       "1           NaN     NaN          NaN           NaN          NaN  ...      NaN   \n",
       "2           NaN     NaN          NaN           NaN          NaN  ...      NaN   \n",
       "3           NaN     NaN          NaN           NaN          NaN  ...      NaN   \n",
       "4           NaN     NaN          NaN           NaN          NaN  ...      NaN   \n",
       "...         ...     ...          ...           ...          ...  ...      ...   \n",
       "1998895  40.348 -68.296  1507.093426  20001.839825  2501.816609  ...  1.09682   \n",
       "1998896  40.324 -68.387  4811.591696  91203.058213  6707.612457  ...  3.49742   \n",
       "1998897  40.324 -68.387  2446.626298  30443.529921  3317.560554  ...  2.46922   \n",
       "1998898  40.273 -68.571  1500.951557  19808.704267  2787.802768  ...  0.61201   \n",
       "1998899  40.273 -68.571  2281.055363  32824.776104  3335.294118  ...  0.57738   \n",
       "\n",
       "         FluoInt  ScatPeak  FluoPeak  NumberOfROIinTrigger  missing_meta_data  \\\n",
       "0            NaN       NaN       NaN                   NaN               True   \n",
       "1            NaN       NaN       NaN                   NaN               True   \n",
       "2            NaN       NaN       NaN                   NaN               True   \n",
       "3            NaN       NaN       NaN                   NaN               True   \n",
       "4            NaN       NaN       NaN                   NaN               True   \n",
       "...          ...       ...       ...                   ...                ...   \n",
       "1998895  0.36801   3.33541   1.37789                   1.0              False   \n",
       "1998896  1.77298   3.35693   3.31523                   1.0              False   \n",
       "1998897  0.90272   3.35900   2.21282                   1.0              False   \n",
       "1998898  0.04541   2.85538   0.37142                   1.0              False   \n",
       "1998899  0.01702   3.33338   0.20818                   1.0              False   \n",
       "\n",
       "         ESDA_exclude  excluded_1    set  binary_label  \n",
       "0               False           1  train      plankton  \n",
       "1               False           1  train      plankton  \n",
       "2               False           1  train      plankton  \n",
       "3               False           1  train      plankton  \n",
       "4               False           1  train      plankton  \n",
       "...               ...         ...    ...           ...  \n",
       "1998895         False           0  train      plankton  \n",
       "1998896         False           0  train      plankton  \n",
       "1998897         False           0  train      plankton  \n",
       "1998898         False           0  train      plankton  \n",
       "1998899         False           0  train      plankton  \n",
       "\n",
       "[1998900 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the csv file of all image lables and filenames\n",
    "\n",
    "csv_path = '/home/azureuser/data/image-file-directory.csv'\n",
    "\n",
    "inventory_df = pd.read_csv(csv_path)\n",
    "inventory_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c76dfff-7504-4087-b6b7-67720969486d",
   "metadata": {},
   "source": [
    "#### Remove rows in the dataframe without metadata (132,781 out of ~2 million)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5fe92d2-0c81-4ce7-8e32-5177d599adcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132781, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inventory_df.missing_meta_data == True\n",
    "inventory_df[inventory_df.missing_meta_data == True].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d8ec1da-ff4e-4392-a9ac-d56342db8afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1866119, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metadata = inventory_df[inventory_df.missing_meta_data == False]\n",
    "df_metadata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d86adec0-f067-40e2-a773-5af1de16673f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional: subsample the full dataframe for workflow testing\n",
    "#df_subsample = inventory_df.iloc[:10000,]\n",
    "#df_subsample = df_metadata.iloc[:1000,]\n",
    "df_subsample = df_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59faedeb-d6fc-4761-a947-736c20fd9b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1866119, 28)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subsample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec7d5b6-0538-4f4e-b6cd-7500e7a74752",
   "metadata": {},
   "source": [
    "#### Create png_path column and 3-column dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57594f18-90c6-4c9f-83cd-adfecd7a8e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8813/1727142688.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_subsample['png_path'] = df_subsample['id'].apply(lambda row : du.buildPNGsName(row))\n"
     ]
    }
   ],
   "source": [
    "# add a column of the png path to the df dataframe\n",
    "df_subsample['png_path'] = df_subsample['id'].apply(lambda row : du.buildPNGsName(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "905a9423-2d6c-4270-86df-58a5c77f4ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe with just the columns of png_path and high_group\n",
    "df_files_labels = df_subsample[['png_path', 'high_group']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b58e6e3-070c-4de3-adba-a483217f0890",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8813/2956326874.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_files_labels['full_path'] = df_files_labels['png_path'].apply(lambda row : os.path.join('/home/azureuser/data/NAAMES_ml/', row))\n"
     ]
    }
   ],
   "source": [
    "# add a column called full_path\n",
    "df_files_labels['full_path'] = df_files_labels['png_path'].apply(lambda row : os.path.join('/home/azureuser/data/NAAMES_ml/', row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0cc2f94b-e156-4381-9d60-97a8e99003b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>png_path</th>\n",
       "      <th>high_group</th>\n",
       "      <th>full_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3348</th>\n",
       "      <td>D20151106T121918_IFCB107/IFCB107D20151106T1219...</td>\n",
       "      <td>Other</td>\n",
       "      <td>/home/azureuser/data/NAAMES_ml/D20151106T12191...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3349</th>\n",
       "      <td>D20151106T121918_IFCB107/IFCB107D20151106T1219...</td>\n",
       "      <td>Other</td>\n",
       "      <td>/home/azureuser/data/NAAMES_ml/D20151106T12191...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3350</th>\n",
       "      <td>D20151106T121918_IFCB107/IFCB107D20151106T1219...</td>\n",
       "      <td>Other</td>\n",
       "      <td>/home/azureuser/data/NAAMES_ml/D20151106T12191...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3351</th>\n",
       "      <td>D20151106T121918_IFCB107/IFCB107D20151106T1219...</td>\n",
       "      <td>Other</td>\n",
       "      <td>/home/azureuser/data/NAAMES_ml/D20151106T12191...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3352</th>\n",
       "      <td>D20151106T121918_IFCB107/IFCB107D20151106T1219...</td>\n",
       "      <td>Other</td>\n",
       "      <td>/home/azureuser/data/NAAMES_ml/D20151106T12191...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998895</th>\n",
       "      <td>D20180412T010113_IFCB107/IFCB107D20180412T0101...</td>\n",
       "      <td>Dinoflagellate</td>\n",
       "      <td>/home/azureuser/data/NAAMES_ml/D20180412T01011...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998896</th>\n",
       "      <td>D20180412T012434_IFCB107/IFCB107D20180412T0124...</td>\n",
       "      <td>Diatom</td>\n",
       "      <td>/home/azureuser/data/NAAMES_ml/D20180412T01243...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998897</th>\n",
       "      <td>D20180412T012434_IFCB107/IFCB107D20180412T0124...</td>\n",
       "      <td>Diatom</td>\n",
       "      <td>/home/azureuser/data/NAAMES_ml/D20180412T01243...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998898</th>\n",
       "      <td>D20180412T021117_IFCB107/IFCB107D20180412T0211...</td>\n",
       "      <td>Dinoflagellate</td>\n",
       "      <td>/home/azureuser/data/NAAMES_ml/D20180412T02111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998899</th>\n",
       "      <td>D20180412T021117_IFCB107/IFCB107D20180412T0211...</td>\n",
       "      <td>Diatom</td>\n",
       "      <td>/home/azureuser/data/NAAMES_ml/D20180412T02111...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1866119 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  png_path      high_group  \\\n",
       "3348     D20151106T121918_IFCB107/IFCB107D20151106T1219...           Other   \n",
       "3349     D20151106T121918_IFCB107/IFCB107D20151106T1219...           Other   \n",
       "3350     D20151106T121918_IFCB107/IFCB107D20151106T1219...           Other   \n",
       "3351     D20151106T121918_IFCB107/IFCB107D20151106T1219...           Other   \n",
       "3352     D20151106T121918_IFCB107/IFCB107D20151106T1219...           Other   \n",
       "...                                                    ...             ...   \n",
       "1998895  D20180412T010113_IFCB107/IFCB107D20180412T0101...  Dinoflagellate   \n",
       "1998896  D20180412T012434_IFCB107/IFCB107D20180412T0124...          Diatom   \n",
       "1998897  D20180412T012434_IFCB107/IFCB107D20180412T0124...          Diatom   \n",
       "1998898  D20180412T021117_IFCB107/IFCB107D20180412T0211...  Dinoflagellate   \n",
       "1998899  D20180412T021117_IFCB107/IFCB107D20180412T0211...          Diatom   \n",
       "\n",
       "                                                 full_path  \n",
       "3348     /home/azureuser/data/NAAMES_ml/D20151106T12191...  \n",
       "3349     /home/azureuser/data/NAAMES_ml/D20151106T12191...  \n",
       "3350     /home/azureuser/data/NAAMES_ml/D20151106T12191...  \n",
       "3351     /home/azureuser/data/NAAMES_ml/D20151106T12191...  \n",
       "3352     /home/azureuser/data/NAAMES_ml/D20151106T12191...  \n",
       "...                                                    ...  \n",
       "1998895  /home/azureuser/data/NAAMES_ml/D20180412T01011...  \n",
       "1998896  /home/azureuser/data/NAAMES_ml/D20180412T01243...  \n",
       "1998897  /home/azureuser/data/NAAMES_ml/D20180412T01243...  \n",
       "1998898  /home/azureuser/data/NAAMES_ml/D20180412T02111...  \n",
       "1998899  /home/azureuser/data/NAAMES_ml/D20180412T02111...  \n",
       "\n",
       "[1866119 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_files_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2acce153-d1d2-47ec-994b-d41e4d19dda9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>png_path</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high_group</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Artefact</th>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chloro</th>\n",
       "      <td>11990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chryso</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cilliate</th>\n",
       "      <td>3386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corrupt</th>\n",
       "      <td>113552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crypto</th>\n",
       "      <td>42171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cyanobacteria</th>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diatom</th>\n",
       "      <td>200173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dictyo</th>\n",
       "      <td>11228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dinoflagellate</th>\n",
       "      <td>135342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eugleno</th>\n",
       "      <td>61572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multiple</th>\n",
       "      <td>29359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not living</th>\n",
       "      <td>80816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>1155984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prymnesio</th>\n",
       "      <td>20176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rhizaria</th>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zoo</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                png_path\n",
       "high_group              \n",
       "Artefact             179\n",
       "Chloro             11990\n",
       "Chryso                13\n",
       "Cilliate            3386\n",
       "Corrupt           113552\n",
       "Crypto             42171\n",
       "Cyanobacteria         48\n",
       "Diatom            200173\n",
       "Dictyo             11228\n",
       "Dinoflagellate    135342\n",
       "Eugleno            61572\n",
       "Multiple           29359\n",
       "Not living         80816\n",
       "Other            1155984\n",
       "Prymnesio          20176\n",
       "Rhizaria             110\n",
       "Zoo                   20"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restructure lables to handle very small groups\n",
    "\n",
    "summary = df_files_labels.groupby('high_group').agg({'png_path' : 'count'})\n",
    "summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f929e77-f371-402c-969c-ef9107fa8e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8813/2001773201.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_files_labels['high_group'] = df_files_labels.apply(lambda row: du.change_class(row, class_dict), axis=1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Chrysophyte --> other\n",
    "# Clumps --> invalid\n",
    "# Cyanobacterium --> other\n",
    "# NOT-CLASSIFIED --> exclude actually \n",
    "# Not-living --> invalid\n",
    "# Rhizaria --> other\n",
    "# Zoo --> other\n",
    "\n",
    "class_dict = {'Artefact' : 'Corrupt',\n",
    "            'Chryso' : 'Other', \n",
    "            'Cyanobacteria' : 'Corrupt',\n",
    "            'Multiple' : 'Other',\n",
    "            'Not living' : 'Corrupt', \n",
    "            'Rhizaria' : 'Other',\n",
    "             'Zoo' : 'Other'}\n",
    "\n",
    "\n",
    "df_files_labels['high_group'] = df_files_labels.apply(lambda row: du.change_class(row, class_dict), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89723bfe-bc9d-42c1-833a-09af9b5098a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>png_path</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high_group</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Chloro</th>\n",
       "      <td>11990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cilliate</th>\n",
       "      <td>3386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corrupt</th>\n",
       "      <td>194595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crypto</th>\n",
       "      <td>42171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diatom</th>\n",
       "      <td>200173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dictyo</th>\n",
       "      <td>11228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dinoflagellate</th>\n",
       "      <td>135342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eugleno</th>\n",
       "      <td>61572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>1185486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prymnesio</th>\n",
       "      <td>20176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                png_path\n",
       "high_group              \n",
       "Chloro             11990\n",
       "Cilliate            3386\n",
       "Corrupt           194595\n",
       "Crypto             42171\n",
       "Diatom            200173\n",
       "Dictyo             11228\n",
       "Dinoflagellate    135342\n",
       "Eugleno            61572\n",
       "Other            1185486\n",
       "Prymnesio          20176"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = df_files_labels.groupby('high_group').agg({'png_path' : 'count'})\n",
    "summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4b6cc14-0097-4973-89c1-e0746b37724b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>png_path</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high_group</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Chloro</th>\n",
       "      <td>11990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cilliate</th>\n",
       "      <td>3386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crypto</th>\n",
       "      <td>42171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diatom</th>\n",
       "      <td>200173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dictyo</th>\n",
       "      <td>11228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dinoflagellate</th>\n",
       "      <td>135342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eugleno</th>\n",
       "      <td>61572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>1185486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prymnesio</th>\n",
       "      <td>20176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                png_path\n",
       "high_group              \n",
       "Chloro             11990\n",
       "Cilliate            3386\n",
       "Crypto             42171\n",
       "Diatom            200173\n",
       "Dictyo             11228\n",
       "Dinoflagellate    135342\n",
       "Eugleno            61572\n",
       "Other            1185486\n",
       "Prymnesio          20176"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove 'Corrupt' examples (194k total) \n",
    "\n",
    "df_reduced = df_files_labels.loc[df_files_labels['high_group'] != 'Corrupt']\n",
    "\n",
    "# look at new class distributions \n",
    "\n",
    "summary = df_reduced.groupby('high_group').agg({'png_path' : 'count'})\n",
    "summary "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323f89fa-5b36-4ff1-9606-df4ad5acdb8d",
   "metadata": {},
   "source": [
    "#### Split and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de6f0a20-4bf3-4adf-9fc2-c0842f9acc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data for testing and training\n",
    "train, validation = train_test_split(df_reduced, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9b6024e-7cfe-43df-884b-f9790d040820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>png_path</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high_group</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Chloro</th>\n",
       "      <td>9523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cilliate</th>\n",
       "      <td>2708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crypto</th>\n",
       "      <td>33676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diatom</th>\n",
       "      <td>160237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dictyo</th>\n",
       "      <td>9043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dinoflagellate</th>\n",
       "      <td>107990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eugleno</th>\n",
       "      <td>49272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>948688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prymnesio</th>\n",
       "      <td>16082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                png_path\n",
       "high_group              \n",
       "Chloro              9523\n",
       "Cilliate            2708\n",
       "Crypto             33676\n",
       "Diatom            160237\n",
       "Dictyo              9043\n",
       "Dinoflagellate    107990\n",
       "Eugleno            49272\n",
       "Other             948688\n",
       "Prymnesio          16082"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at training distribution \n",
    "\n",
    "train_summary = train.groupby('high_group').agg({'png_path' : 'count'})\n",
    "train_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e657613-38cf-4332-81a7-a9c9f00f4cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly downsample 'Other' images keeping 200k of >900k \n",
    "\n",
    "other = train.loc[train['high_group'] == 'Other']\n",
    "not_other = train.loc[train['high_group'] != 'Other']\n",
    "other_keep = other.sample(n=200000)\n",
    "train = pd.concat([not_other, other_keep])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a4498b9-cda3-4369-85dc-d73054864f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>png_path</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high_group</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Chloro</th>\n",
       "      <td>9523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cilliate</th>\n",
       "      <td>2708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crypto</th>\n",
       "      <td>33676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diatom</th>\n",
       "      <td>160237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dictyo</th>\n",
       "      <td>9043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dinoflagellate</th>\n",
       "      <td>107990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eugleno</th>\n",
       "      <td>49272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prymnesio</th>\n",
       "      <td>16082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                png_path\n",
       "high_group              \n",
       "Chloro              9523\n",
       "Cilliate            2708\n",
       "Crypto             33676\n",
       "Diatom            160237\n",
       "Dictyo              9043\n",
       "Dinoflagellate    107990\n",
       "Eugleno            49272\n",
       "Other             200000\n",
       "Prymnesio          16082"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at new distribution of training \n",
    "\n",
    "train_summary = train.groupby('high_group').agg({'png_path' : 'count'})\n",
    "train_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89e4a0be-c4ac-4b43-8fab-6fc4ea18bca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsample the low classes in the training example set \n",
    "\n",
    "# classes = list(set(v.label))\n",
    "# upsample = [] \n",
    "# for c in classes: \n",
    "#     if len(train.loc[train['label'] == c]) < 20000: \n",
    "#         upsample.append(c)\n",
    "\n",
    "# for c in upsample: \n",
    "#     new_rows = pd.concat(add_training_examples(c, 20000, train))\n",
    "#     train = pd.concat([train, new_rows])\n",
    "\n",
    "# train.groupby('label').agg({'image_path' : 'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "590de330-9a5b-46f7-88ae-62e2cd610b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- \n",
    "# one hot encode the labels \n",
    "\n",
    "lb = LabelBinarizer()\n",
    "labels = set(df_reduced.high_group)\n",
    "lb.fit(list(labels))\n",
    "batch_size = 100\n",
    "#batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ff6102-37e7-428a-acdb-f5e653a4ff63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f31e563c-9385-4890-9d67-17403ca3f050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate generators \n",
    "\n",
    "trainGen = du.image_generator(train, batch_size, lb)\n",
    "validationGen = du.image_generator(validation, batch_size, lb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f121e2b-ae18-4910-9802-7af106bc0a62",
   "metadata": {},
   "source": [
    "#### Define CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ac19d1a-b6a1-49a5-8c98-a2c1fdd3e540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function ml_models.create_cnn_model_A1(width, height, depth, filters=(32, 16, 64, 32, 128, 128, 64, 256, 256, 128), regress=False)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_models.create_cnn_model_A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c87aafb-985b-46e6-b293-34806741b8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-31 20:41:45.952345: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2023-03-31 20:41:45.987755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0001:00:00.0 name: Tesla V100-PCIE-16GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2023-03-31 20:41:45.988066: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-03-31 20:41:45.990005: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2023-03-31 20:41:45.993584: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2023-03-31 20:41:45.994030: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2023-03-31 20:41:45.995989: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-03-31 20:41:45.996828: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-03-31 20:41:45.997035: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /anaconda/envs/azureml_py38/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2023-03-31 20:41:45.997049: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1598] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-03-31 20:41:45.997691: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2023-03-31 20:41:46.004276: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2593990000 Hz\n",
      "2023-03-31 20:41:46.004594: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbb60000b60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-03-31 20:41:46.004614: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2023-03-31 20:41:46.005947: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-03-31 20:41:46.005964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      \n"
     ]
    }
   ],
   "source": [
    "# define and compile cnn with function \n",
    "# should do layer by layer going forward for legibility\n",
    "\n",
    "cnn = ml_models.create_cnn_model_A1(128, 128, 1, regress=False)\n",
    "x = Dense(1000, activation=\"relu\")(cnn.output)\n",
    "x = Dropout(rate=0.1)(x)\n",
    "x = Dense(len(labels), activation=\"softmax\")(x)\n",
    "model = Model(inputs=cnn.input, outputs=x)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96244130-80ec-45bb-8e89-08ee5e9c3a8f",
   "metadata": {},
   "source": [
    "#### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee1faeae-79a5-421e-becf-f7f868738b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "totalTrain = len(train)\n",
    "totalVal = len(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37085d51-5842-4243-9ff3-a7fce179d21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-31 20:41:51.725451: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session started.\n",
      "2023-03-31 20:41:51.725525: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1363] Profiler found 1 GPUs\n",
      "2023-03-31 20:41:51.725750: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcupti.so.10.1'; dlerror: libcupti.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /anaconda/envs/azureml_py38/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2023-03-31 20:41:51.725770: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1408] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2023-03-31 20:41:51.725781: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1447] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2023-03-31 20:41:51.725801: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1430] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI could not be loaded or symbol could not be found.\n"
     ]
    }
   ],
   "source": [
    "# When training with Keras's Model.fit(), adding the tf.keras.callbacks.\n",
    "# TensorBoard callback ensures that logs are created and stored. \n",
    "# Additionally, enable histogram computation every epoch with histogram_freq=1 (this is off by default)\n",
    "\n",
    "#Place the logs in a timestamped subdirectory to allow easy selection of different training runs.\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b161d59-2164-4efd-a4dc-bfe2083afa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "480b1685-822e-4595-8b6f-cfa389d7e17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training simple network...\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:6\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:66\u001b[0m, in \u001b[0;36menable_multi_worker.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_method_wrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     65\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_multi_worker_mode():  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m   \u001b[38;5;66;03m# Running inside `run_distribute_coordinator` already.\u001b[39;00m\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dc_context\u001b[38;5;241m.\u001b[39mget_current_worker_context():\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:802\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    794\u001b[0m   (x, y, sample_weight), validation_data \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    795\u001b[0m       data_adapter\u001b[38;5;241m.\u001b[39mtrain_validation_split((x, y, sample_weight),\n\u001b[1;32m    796\u001b[0m                                           validation_split\u001b[38;5;241m=\u001b[39mvalidation_split,\n\u001b[1;32m    797\u001b[0m                                           shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[1;32m    799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy\u001b[38;5;241m.\u001b[39mscope(), \\\n\u001b[1;32m    800\u001b[0m      training_utils\u001b[38;5;241m.\u001b[39mRespectCompiledTrainableState(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    801\u001b[0m   \u001b[38;5;66;03m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[39;00m\n\u001b[0;32m--> 802\u001b[0m   data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataHandler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m      \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m      \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m      \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    807\u001b[0m \u001b[43m      \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[43m      \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    809\u001b[0m \u001b[43m      \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[43m      \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    811\u001b[0m \u001b[43m      \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    813\u001b[0m \u001b[43m      \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    814\u001b[0m \u001b[43m      \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    815\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    817\u001b[0m   \u001b[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[1;32m    818\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py:1100\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model)\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m select_data_adapter(x, y)\n\u001b[0;32m-> 1100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter \u001b[38;5;241m=\u001b[39m \u001b[43madapter_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1104\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribution_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mds_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1114\u001b[0m strategy \u001b[38;5;241m=\u001b[39m ds_context\u001b[38;5;241m.\u001b[39mget_strategy()\n\u001b[1;32m   1115\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter\u001b[38;5;241m.\u001b[39mget_dataset()\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py:772\u001b[0m, in \u001b[0;36mGeneratorDataAdapter.__init__\u001b[0;34m(self, x, y, sample_weights, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28msuper\u001b[39m(GeneratorDataAdapter, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(x, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    770\u001b[0m \u001b[38;5;66;03m# Since we have to know the dtype of the python generator when we build the\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;66;03m# dataset, we have to look at a batch to infer the structure.\u001b[39;00m\n\u001b[0;32m--> 772\u001b[0m peek, x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_peek_and_restore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    773\u001b[0m assert_not_namedtuple(peek)\n\u001b[1;32m    774\u001b[0m peek \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_standardize_batch(peek)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py:830\u001b[0m, in \u001b[0;36mGeneratorDataAdapter._peek_and_restore\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_peek_and_restore\u001b[39m(x):\n\u001b[0;32m--> 830\u001b[0m   peek \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    831\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m peek, itertools\u001b[38;5;241m.\u001b[39mchain([peek], x)\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# train model and save history object \n",
    "\n",
    "' training in smaller increments to monitor progress '\n",
    "\n",
    "print(\"[INFO] training simple network...\")\n",
    "H = model.fit(\n",
    "    trainGen,\n",
    "    steps_per_epoch=totalTrain // batch_size,\n",
    "    validation_data=validationGen,\n",
    "    validation_steps=totalVal // batch_size,\n",
    "    #epochs=10,\n",
    "    epochs=16)#,\n",
    "#    callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "58c18474-bf99-487f-b5c3-09cd72d19684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# save model weights and structure from history object \n",
    "\n",
    "''' save model and weights '''\n",
    "model_json = model.to_json()\n",
    "with open(\"model-test-cnn-v1.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "model.save_weights(\"model-test-cnn-v1.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "45379f5b-edfa-4f3e-abc4-2cf8a2ed8aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed 1 of 10 testing subsets\n",
      "completed 2 of 10 testing subsets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@220737.610] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/azureuser/data/NAAMES_ml/D20160513T121618_IFCB107/IFCB107D20160513T121618P02005.png'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [111]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     row \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[i]\n\u001b[1;32m     13\u001b[0m     input_path \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull_path\u001b[39m\u001b[38;5;124m'\u001b[39m] \n\u001b[0;32m---> 14\u001b[0m     image_data\u001b[38;5;241m.\u001b[39mappend(\u001b[43mdu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     16\u001b[0m test_input \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(image_data)\n",
      "File \u001b[0;32m~/notebooks/alichase/ml-workflow/data_utils.py:128\u001b[0m, in \u001b[0;36mpreprocess_input\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_input\u001b[39m(image):\n\u001b[1;32m    127\u001b[0m     fixed_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m\n\u001b[0;32m--> 128\u001b[0m     image_size \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[:\u001b[38;5;241m2\u001b[39m] \n\u001b[1;32m    129\u001b[0m     ratio \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(fixed_size)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mmax\u001b[39m(image_size)\n\u001b[1;32m    130\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m([\u001b[38;5;28mint\u001b[39m(x\u001b[38;5;241m*\u001b[39mratio) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m image_size])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# predicting with the trained model before exporting & reloading etc\n",
    "\n",
    "test_split = np.array_split(validation, 10)\n",
    "test_preds = []\n",
    "n = 1\n",
    "for df in test_split: \n",
    "    labels = df['high_group'].values\n",
    "    test_labels = lb.fit_transform(labels)\n",
    "    v_dat = df.drop(['full_path', 'high_group'], axis=1).values\n",
    "    image_data = []\n",
    "    for i in range(len(df)): \n",
    "        row = df.iloc[i]\n",
    "        input_path = row['full_path'] \n",
    "        image_data.append(du.preprocess_input(cv2.imread(input_path)))\n",
    "        #\n",
    "    test_input = np.array(image_data)\n",
    "    predictions = model.predict(test_input)\n",
    "    pred_frame = pd.DataFrame(predictions)\n",
    "    pred_frame['full_path'] = df['full_path'].values.tolist()\n",
    "    top_1 = [np.argmax(i) for i in predictions]\n",
    "    df['pred_label'] = top_1\n",
    "    df['true_label'] = [np.argmax(i) for i in test_labels]\n",
    "    df['is_correct'] = df.apply(lambda row: du.is_correct(row), axis=1)\n",
    "    df_out = pd.merge(df, pred_frame, on = 'full_path', how='left')\n",
    "    test_preds.append(df_out)\n",
    "    print('completed ' + str(n) + ' of 10 testing subsets')\n",
    "    n +=1 \n",
    "    del image_data\n",
    "\n",
    "\n",
    "\n",
    "test_eval = pd.concat(test_preds)\n",
    "\n",
    "if len(test_eval) == len(test):\n",
    "    print('generated predictions for all examples in testing dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "254f7ffc-408c-492f-aadd-3f33825f24ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.891753613948822,\n",
       " 0.8972428441047668,\n",
       " 0.9097256064414978,\n",
       " 0.8927979469299316,\n",
       " 0.8848884105682373,\n",
       " 0.9043503999710083,\n",
       " 0.9142099618911743,\n",
       " 0.8593658804893494,\n",
       " 0.8864887952804565,\n",
       " 0.9143206477165222,\n",
       " 0.8925104737281799,\n",
       " 0.8375950455665588,\n",
       " 0.8563655018806458,\n",
       " 0.8182103633880615,\n",
       " 0.8913558125495911,\n",
       " 0.9075840711593628]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at history objct for training hueristics\n",
    "\n",
    "print(H.history.keys())\n",
    "H.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fc3a4609-06f1-4367-9c1c-10b07a7f6984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8396170735359192,\n",
       " 0.8903592228889465,\n",
       " 0.9028232097625732,\n",
       " 0.9102937579154968,\n",
       " 0.9148202538490295,\n",
       " 0.9192448854446411,\n",
       " 0.9226541519165039,\n",
       " 0.926394522190094,\n",
       " 0.9293216466903687,\n",
       " 0.932408332824707,\n",
       " 0.9357650279998779,\n",
       " 0.9390724301338196,\n",
       " 0.9415462017059326,\n",
       " 0.9449062347412109,\n",
       " 0.9473868012428284,\n",
       " 0.9500592350959778]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "87f01de5-5356-45c6-93b6-f7ce1732cd57",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_eval' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [110]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# --\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# obtain accruacy for final model prediction \u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28msum\u001b[39m(\u001b[43mtest_eval\u001b[49m\u001b[38;5;241m.\u001b[39mis_correct))\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mlen\u001b[39m(test_eval))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# # -- \u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# # make reference for reviewing by class model accuracy \u001b[39;00m\n\u001b[1;32m     10\u001b[0m test_summ \u001b[38;5;241m=\u001b[39m test_eval[[ \u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_path\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred_label\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrue_label\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_correct\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m                                \u001b[38;5;241m0\u001b[39m,                        \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     12\u001b[0m                                \u001b[38;5;241m2\u001b[39m,                        \u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m                                \u001b[38;5;241m8\u001b[39m,                        \u001b[38;5;241m9\u001b[39m,\n\u001b[1;32m     16\u001b[0m                               \u001b[38;5;241m10\u001b[39m]]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_eval' is not defined"
     ]
    }
   ],
   "source": [
    "# --\n",
    "# obtain accruacy for final model prediction \n",
    "\n",
    "float(sum(test_eval.is_correct))/float(len(test_eval))\n",
    "\n",
    "\n",
    "# # -- \n",
    "# # make reference for reviewing by class model accuracy \n",
    "\n",
    "test_summ = test_eval[[ u'image_path', u'label', u'pred_label', u'true_label', u'is_correct',\n",
    "                               0,                        1,\n",
    "                               2,                        3,\n",
    "                               4,                        5,\n",
    "                               6,                        7,\n",
    "                               8,                        9,\n",
    "                              10]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "754db631-5f30-476a-bd18-6a8088a6df73",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_summ' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [112]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# add top 5 accuracy score to output & build by class summary frame\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m test_summ[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtop_5\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtest_summ\u001b[49m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: get_top_5(row), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m test_agg \u001b[38;5;241m=\u001b[39m test_summ\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhigh_group\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39magg({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpng_path\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_correct\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtop_5\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m      6\u001b[0m test_agg\u001b[38;5;241m.\u001b[39mreset_index(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_summ' is not defined"
     ]
    }
   ],
   "source": [
    "# add top 5 accuracy score to output & build by class summary frame\n",
    "\n",
    "test_summ['top_5'] = test_summ.apply(lambda row: get_top_5(row), axis=1)\n",
    "\n",
    "test_agg = test_summ.groupby('high_group').agg({'png_path' : 'count', 'is_correct' : 'sum', 'top_5' : 'sum'})\n",
    "test_agg.reset_index(inplace=True)\n",
    "test_agg.columns = ['high_group', 'top_1', 'top_5', 'n_obs']\n",
    "test_agg['top_1_acc'] = test_agg.apply(lambda row: get_percent(row, 'top_1'), axis=1)\n",
    "test_agg['top_5_acc'] = test_agg.apply(lambda row: get_percent(row, 'top_5'), axis=1)\n",
    "\n",
    "\n",
    "test_summ.to_csv('./model-summary-cnn-v1.csv', index=False)\n",
    "test_agg.sort_values('top_1_acc', ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5f71f0e7-a548-425d-89c2-09ac3d7959f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.training.Model at 0x7f37b505f190>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc9a53b-f22d-4288-8075-230f9b45e5f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py38",
   "language": "python",
   "name": "conda-env-azureml_py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
